<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Transfer Learning with ConvNext, HuggingFace, and Ignite</title>
  <meta name="description" content="The outcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts compete fav...">

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  
  
<!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: [
      "MathMenu.js",
      "MathZoom.js",
      "AssistiveMML.js",
      "a11y/accessibility-menu.js"
    ],
    jax: ["input/TeX", "output/CommonHTML"],
    TeX: {
      extensions: [
        "AMSmath.js",
        "AMSsymbols.js",
        "noErrors.js",
        "noUndefined.js",
      ]
    }
  });
</script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>  


  <link rel="stylesheet" type="text/css" href="/css/tufte.css">
  <!-- <link rel="stylesheet" type="text/css" href="/css/print.css" media="print"> -->

  <link rel="canonical" href="/articles/22/ConvNext-transfer">

  <link rel="alternate" type="application/rss+xml" title="Dylan's Blog" href="/feed.xml" />

  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üßô</text></svg>">
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
	<a href="/"><img class="badge" src="/assets/img/badge.png" alt="CH"></a>
	
		
  	
		
		    
		      <a href="/">posts</a>
		    
	    
  	
		
		    
		      <a href="/about/">About</a>
		    
	    
  	
		
		    
		      <a href="/css/print.css"></a>
		    
	    
  	
		
  	
	</nav>
</header>
    <article class="group">
      <h1>Transfer Learning with ConvNext, HuggingFace, and Ignite</h1>
<p class="subtitle">June 18, 2022</p>

<div class="epigraph"><blockquote><p>The outcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8% ImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection and ADE20K segmentation, while maintaining the simplicity and efficiency of standard ConvNets.</p><footer>Zhuang Liu et al., <cite>A ConvNet for the 2020s</cite></footer></blockquote></div>

<p><span class="newthought">TLDR:</span>  I put together a quick-n-dirty example (<a href="https://gist.github.com/dylanv/9b98410ec9cf41f61c4d1ad6baee8822">Github gist here</a>) if you don‚Äôt feel like reading.
<!--more--></p>

<p><span class="newthought">Recently, Jeremy Howard</span>  <a href="https://twitter.com/jeremyphoward/status/1537718111251468288">tweeted</a> about some of his experiments with finding which image models are best for <a href="https://www.kaggle.com/code/jhoward/which-image-models-are-best">training from scratch</a> and for <a href="https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning">fine-tuning</a>.
A particular standout was the ConvNeXt model  <label for="one" class="margin-toggle sidenote-number"></label><input type="checkbox" id="one" class="margin-toggle" /><span class="sidenote">Arxiv paper <a href="https://arxiv.org/abs/2201.03545">here</a>. It‚Äôs pretty readable. </span> which is a ‚Äúmodernised‚Äù resnet designed to be more similar to transformer models.</p>

<p>This led to a reasonably efficient model that seems to work great on a wide variety of tasks. The <a href="https://github.com/facebookresearch/ConvNeXt">official repo</a> is pretty helpful and it‚Äôs built into <a href="https://github.com/rwightman/pytorch-image-models">timm</a>.</p>

<figure><img src="/assets/convnext/comparison.jpg" /><figcaption class="maincolumn-figure">Lol (from <a href="https://twitter.com/giffmana/status/1538617065048788997">Lucas Beyer on twitter</a></figcaption></figure>

<p><span class="newthought">Lately I‚Äôve been spending</span>  way too much time messing around with models from <a href="https://huggingface.co/">Hugging Face</a>.
I‚Äôve always been a big transfer learning fan, get great results quickly with less compute seems like a no-brainer. 
So I thought this is a good excuse to see how hard it is to get into the inner workings of HuggingFace models 
<label for="two" class="margin-toggle sidenote-number"></label><input type="checkbox" id="two" class="margin-toggle" /><span class="sidenote">It‚Äôs probably more sensible to use timm but HF also comes with some very useful bells and whistles </span>
and to see if my beloved resnets have been finally replaced.</p>

<p><span class="newthought">I decided</span>  to go with the <a href="https://huggingface.co/facebook/convnext-tiny-224">convnext-tiny-224</a> variant. Who doesn‚Äôt love a small and performant model?</p>

<p>Grabbing the model is as easy as: <label for="three" class="margin-toggle sidenote-number"></label><input type="checkbox" id="three" class="margin-toggle" /><span class="sidenote">God I love how streamlined some of this is these days. </span></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">ConvNextFeatureExtractor</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"facebook/convnext-tiny-224"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ConvNextForImageClassification</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"facebook/convnext-tiny-224"</span><span class="p">)</span>
</code></pre></div></div>
<p>If we go dig around in the guts of it, we can see that replacing the head is as easy as setting <code class="language-plaintext highlighter-rouge">classifier</code> on the model.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ConvNextForImageClassification</span><span class="p">(</span><span class="n">ConvNextPreTrainedModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">num_labels</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">convnext</span> <span class="o">=</span> <span class="n">ConvNextModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="c1"># Classifier head
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">config</span><span class="p">.</span><span class="n">num_labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">config</span><span class="p">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">nn</span><span class="p">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="c1"># Initialize weights and apply final processing
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">post_init</span><span class="p">()</span>
</code></pre></div></div>
<p>Cool, so freeze everything, replace the classifier, and you‚Äôre off to the races? Nope, unfortunatley nothing is ever that easy and Ignite wants your model to return Tensors and the HuggingFace model returns a <code class="language-plaintext highlighter-rouge">ImageClassifierOutputWithNoAttention</code> object <label for="four" class="margin-toggle sidenote-number"></label><input type="checkbox" id="four" class="margin-toggle" /><span class="sidenote">Or optionally a tuple, but that doesn‚Äôt actually help at all for the most part. </span>
My first thought was to just set a custom train step and grab the logits there, something like:
<label for="one" class="margin-toggle"> ‚äï</label><input type="checkbox" id="one" class="margin-toggle" /><span class="marginnote">Another thought is whether you actually want the model in train mode. Should you update layer norms etc. when transfer learning? </span></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># Get a tensor from the return dict
</span>    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="n">logits</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">train_step</span><span class="p">)</span>
</code></pre></div></div>
<p>This works as long as you don‚Äôt have any other evaluators or whatever running, which seems fairly unlikely in practice.
<label for="five" class="margin-toggle sidenote-number"></label><input type="checkbox" id="five" class="margin-toggle" /><span class="sidenote">Also we don‚Äôt want to be writing vanilla training loops like cavemen. </span></p>

<p><span class="newthought">In the end</span>  the cleanest method was to just wrap the model so that it always returns tensors.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">IgniteConvNext</span><span class="p">(</span><span class="n">ConvNextForImageClassification</span><span class="p">):</span>
    <span class="s">"""Wrap a HuggingFace ConvNext classifier so that it can be used with Ignite."""</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pixel_values</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">FloatTensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">().</span><span class="n">forward</span><span class="p">(</span><span class="n">pixel_values</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>
<p>This has the other advantage of keeping all the nice saving/loading whatver else you get from the HuggingFace model.</p>

<p>If we‚Äôre careful setting things up, we can even keep our config matching the model:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Grab the dataset first so we know our classes. Should have separate folders for each class
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">ImageFolder</span><span class="p">(</span><span class="n">dataset_folder</span><span class="p">)</span>

<span class="c1"># Grab the pretrained model from Huggingface
</span><span class="n">model</span> <span class="o">=</span> <span class="n">IgniteConvNext</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">)</span>

<span class="c1"># Swap out the classifier
</span><span class="n">model</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">classes</span><span class="p">))</span>
<span class="c1"># Update the config
</span><span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">label2id</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">class_to_idx</span>
<span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">id2label</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">.</span><span class="n">class_to_idx</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">classes</span><span class="p">)</span>
</code></pre></div></div>

<p>Then freeze the model:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Freeze all the parameters
</span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>
<span class="c1"># Make sure the classifier part is set to have gradients
</span><span class="n">model</span><span class="p">.</span><span class="n">classifier</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>
</code></pre></div></div>
<p>Don‚Äôt forget to only add the classifier parameters to your optimizer</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">classifier</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
</code></pre></div></div>
<p>A really nice part of using HuggingFace is we can also get the feature extractor nice and easy, and then setup of vanilla torch transforms correctly:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The model comes with an associated feature extractor so grab the transform params from it
</span><span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">ConvNextFeatureExtractor</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">)</span>
<span class="n">dataset</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">T</span><span class="p">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">T</span><span class="p">.</span><span class="n">AutoAugment</span><span class="p">(</span><span class="n">T</span><span class="p">.</span><span class="n">AutoAugmentPolicy</span><span class="p">.</span><span class="n">IMAGENET</span><span class="p">),</span>
        <span class="n">T</span><span class="p">.</span><span class="n">PILToTensor</span><span class="p">(),</span>
        <span class="n">T</span><span class="p">.</span><span class="n">ConvertImageDtype</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">),</span>
        <span class="c1"># Note these are grabbed from the feature_extractor
</span>        <span class="n">T</span><span class="p">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">feature_extractor</span><span class="p">.</span><span class="n">image_mean</span><span class="p">,</span> <span class="n">feature_extractor</span><span class="p">.</span><span class="n">image_std</span><span class="p">),</span>
        <span class="n">T</span><span class="p">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">feature_extractor</span><span class="p">.</span><span class="n">size</span><span class="p">,</span> <span class="n">feature_extractor</span><span class="p">.</span><span class="n">size</span><span class="p">)),</span>
    <span class="p">]</span>
    <span class="p">)</span>
</code></pre></div></div>
<p>With that you should be off to the races. From my experiments ConvNext does seem to give a performance bump and I like how efficient the smaller versions are. 
<label for="six" class="margin-toggle sidenote-number"></label><input type="checkbox" id="six" class="margin-toggle" /><span class="sidenote">It‚Äôs also nice getting a working model in 10 minutes on your local machine. </span>
Probably going to be using this a lot more in the future.</p>

<h2 id="full-example">Full Example</h2>

<script src="https://gist.github.com/dylanv/9b98410ec9cf41f61c4d1ad6baee8822.js"></script>




    </article>
    <span class="print-footer">Transfer Learning with ConvNext, HuggingFace, and Ignite - June 18, 2022 - Dylan Verrezen</span>
    <footer>
  <hr class="slender">
  <!-- <ul class="footer-links">
    <li><a href="mailto:hate@spam.net"><span class="icon-mail3"></span></a></li>    
      
  </ul> -->
<div class="credits">
<span>&copy; 2022 &nbsp;&nbsp;DYLAN VERREZEN</span></br> <br>
<!-- <span>This site created with the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme for Machine learning, software, and a bit of everything </a> in <a href="//jekyllrb.com">Jekyll</a>.</span>  -->
</div>  
</footer>
  </body>
</html>
